{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c334a0e-995a-49c3-a130-60f24b37c789",
   "metadata": {},
   "source": [
    "# Functions for making the dataframes for the VADs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "006cb371-0942-4268-8cd1-356a7e5ad822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyart\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "# from radarcalc import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import metpy.calc as mpcalc\n",
    "import metpy\n",
    "import metpy.plots\n",
    "from metpy.units import units\n",
    "import cartopy.crs as ccrs\n",
    "import gc\n",
    "from astropy.convolution import convolve\n",
    "from boto.s3.connection import S3Connection\n",
    "import tempfile\n",
    "import copy\n",
    "import matplotlib\n",
    "import xarray as xr\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66d9812b-5800-432f-a1fd-e5631506335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dealias_Ka(radar,PPIGC_flag=False):\n",
    "    '''\n",
    "    This function aims to take care of all the nitty gritty customizations of pyarts dealiasing specifically for TTUKa radar data.\n",
    "\n",
    "    Parameter: radar (pyart object), PPIGC_flag (boolean *kwarg)\n",
    "    Returns: radar (pyart object) with corrected_velocity field and velocity_texture field added on\n",
    "\n",
    "    How it works:\n",
    "    1. Calculates velocity texture and creates a histogram based on all of the magnitudes of textures at each bin for the entire volume\n",
    "    2. loops through each indivual sweep\n",
    "    3. infinite loop to iterate between the minimum amount of texture between textures 1 and 6 and the maximum amount of texture in the histogram, with 0.5 m/s steps\n",
    "    4. Each iteration, create a gatefilter that filters the bins above that texture value and dealias it with the gatefilter to ignore the high textured regions\n",
    "    5. If the maximum texture is reached before breaking, set the gatefilter to mask textures above 12 m/s\n",
    "    6. if the scan is an RHI, run a 2 pass variance filter along each ray.\n",
    "        This convolves a 71 sized boxcar with the data, and if the difference between the point the boxcar is centered on and the mean of the boxcar is greater than the nyquist, then add/subtract 2*nyquist to that point\n",
    "    7. Then, take the difference between the mean of the bottom 4 rays of the dealiased velocity in the RHI and the bottom 4 rays of the aliased velocity\n",
    "    8. If the absolute difference is larger than the nyquist, the either subtract 2* nyquist or add 2*nyquist to the entire sweep and break the loop\n",
    "    9. If the absolute difference is less than the nyquist, no fixes need to be applied, break the loop\n",
    "    10. If the scan is a PPI, do steps 8 and 9, but skip steps 6 and 7\n",
    "    11. Outside the infinite loop, add the option of the PPIGC_flag, a boolean flag that will help maintain ground clutter in PPIs at 0 m/s\n",
    "        This works by identifying regions of very low spectrum width (<0.1 m/s), and setting the velocity in those regions = 0. Please note, this may introduce artificial speckles of 0 in real data, where spectrum width is noisy\n",
    "    12. Apply the alias fix algorithm which convolves a boxcar of specified boxcar of size 9 with the data, and if the variance between the middle pixel of interest and the mean is greater than the nyquist, then flip it back over\n",
    "    12. At the end of each sweep, assign the data from that processed sweep into a dictionary, then add the dictionary as the corrected_velocity field.\n",
    "    \n",
    "    The aforementioned method is FAR from perfect, but is as robust as I can do currently. One thing to improve this though is to use the UNRAVEL algorithm: https://github.com/vlouf/dealias\n",
    "    The UNRAVEL algorithm shows remarkable error characteristics compared to \"competitors\", possibly at a time cost, which isn't a HUGE deal for us. Downside is it may not work for our \"volumes\" since they are temporally uncorrelated and are not full volumes through the atmosphere\n",
    "    '''\n",
    "    \n",
    "    vel_texture = pyart.retrieve.calculate_velocity_texture(radar, vel_field='velocity', wind_size=3)\n",
    "    radar.add_field('velocity_texture', vel_texture, replace_existing=True)\n",
    "    hist, bins = np.histogram(radar.fields['velocity_texture']['data'][~np.isnan(radar.fields['velocity_texture']['data'])], bins=150)\n",
    "    bins = (bins[1:]+bins[:-1])/2.0\n",
    "    gatefilter = pyart.filters.GateFilter(radar)\n",
    "    velocity_dealiased = pyart.correct.dealias_region_based(radar, vel_field='velocity', nyquist_vel=radar.instrument_parameters['nyquist_velocity']['data'][0], centered=True) #standin, data will be replaced\n",
    "\n",
    "    for swp_id in range(radar.nsweeps):\n",
    "        #get indices from beginning and ending of sweep\n",
    "        sw_start = radar.sweep_start_ray_index['data'][swp_id]\n",
    "        sw_end = radar.sweep_end_ray_index['data'][swp_id]+1\n",
    "        # if the scan is a gentle scan we skip it\n",
    "        if ((radar.nsweeps==1) & (np.around(radar.fixed_angle['data'][0],decimals=0)==37.0) & (np.abs(np.mean(radar.fields['velocity']['data']))<0.1) & (np.std(radar.fields['velocity']['data'])<1)):\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "\n",
    "            counter = 0\n",
    "            while True: #do an infinite loop and either break it when the data is unfolded correctly or when the max texture is reached\n",
    "                #if the bin with the lowest count between textures 1 and 6 + i*0.5 is less than the maximum amount of bins\n",
    "                if bins[np.where(hist==np.min(hist[find_nearest(bins,1):find_nearest(bins,6)]))[0][0]]+counter*0.5 < np.amax(bins):\n",
    "                    gatefilter.exclude_above('velocity_texture', bins[np.where(hist==np.min(hist[find_nearest(bins,1):find_nearest(bins,6)]))[0][0]]+counter*0.5)\n",
    "                    nyq = radar.instrument_parameters['nyquist_velocity']['data'][0]\n",
    "                    vede = pyart.correct.dealias_region_based(radar, vel_field='velocity', nyquist_vel=nyq,\n",
    "                                                                            centered=True, gatefilter=gatefilter)\n",
    "                else:\n",
    "                    gatefilter.exclude_above('velocity_texture', 12)#bins[np.where(hist==np.min(hist[find_nearest(bins,1):find_nearest(bins,6)]))[0][0]])\n",
    "                    nyq = radar.instrument_parameters['nyquist_velocity']['data'][0]\n",
    "                    vede = pyart.correct.dealias_region_based(radar, vel_field='velocity', nyquist_vel=nyq,\n",
    "                                                                            centered=True, gatefilter=gatefilter)\n",
    "    \n",
    "    \n",
    "                np.ma.set_fill_value(vede['data'], np.nan)\n",
    "                #extract mask so we can apply the correct gatefilters on later\n",
    "                mask=np.ma.getmask(vede['data'])\n",
    "    \n",
    "                #apply mask to velocity field and fix the small blips from dealiasing\n",
    "                if radar.scan_type == 'rhi':\n",
    "                    #pass 1 of variance filtering along the ray.\n",
    "                    #Convolves a 71 sized boxcar with the data, and if the difference between the point the boxcar is centered on and the mean of the boxcar is greater than the nyquist, then add/subtract 2*nyquist to that point\n",
    "                    vel = vede['data'].filled()\n",
    "    \n",
    "                    for sw in range(np.shape(vel)[0]):\n",
    "                        mean = convolve(vel[sw,:],np.ones(71))\n",
    "                        var = vel[sw,:]-mean\n",
    "                        high_idx = var > nyq\n",
    "                        low_idx = var < -nyq\n",
    "                        vel[sw,:][high_idx] = vel[sw,:][high_idx] - 2*nyq\n",
    "                        vel[sw,:][low_idx] = vel[sw,:][low_idx] + 2*nyq\n",
    "                    vede['data']=np.ma.masked_array(vel,mask=mask,fill_value=np.nan)\n",
    "    \n",
    "                    #pass 2 of variance filtering along the ray. In case there are errant folds than need to be folded back\n",
    "                    vel = vede['data'].filled()\n",
    "                    for sw in range(np.shape(vel)[0]):\n",
    "                        mean = convolve(vel[sw,:],np.ones(71))\n",
    "                        var = vel[sw,:]-mean\n",
    "                        high_idx = var > nyq\n",
    "                        low_idx = var < -nyq\n",
    "                        vel[sw,:][high_idx] = vel[sw,:][high_idx] - 2*nyq\n",
    "                        vel[sw,:][low_idx] = vel[sw,:][low_idx] + 2*nyq\n",
    "                    vede['data']=np.ma.masked_array(vel,mask=mask,fill_value=np.nan)\n",
    "\n",
    "                    #find means of the bottom 4 rays of the RHI(should be close to 0) and compare the dealiased velocities to the aliased velocities\n",
    "                    np.ma.set_fill_value(radar.fields['velocity']['data'], np.nan)\n",
    "                    meanvelal = np.mean(radar.fields['velocity']['data'][sw_start:sw_start+4,:].filled()[~np.isnan(radar.fields['velocity']['data'][sw_start:sw_start+4,:].filled())])\n",
    "                    meanveldeal = np.mean(vede['data'][sw_start:sw_start+4,:].filled()[~np.isnan(vede['data'][sw_start:sw_start+4,:].filled())])\n",
    "                    if np.abs(meanvelal-meanveldeal) < nyq: #nyq is an arbitrary threshold and should be tuned\n",
    "                        break\n",
    "                    if bins[np.where(hist==np.min(hist[find_nearest(bins,1):find_nearest(bins,6)]))[0][0]]+counter*0.5 < np.amax(bins):\n",
    "                        if (meanvelal-meanveldeal) > 0:\n",
    "                            vede['data'][sw_start:sw_end,:] += 2*nyq\n",
    "                        else:\n",
    "                            vede['data'][sw_start:sw_end,:] -= 2*nyq\n",
    "                        break\n",
    "                if radar.scan_type == 'ppi':\n",
    "                    np.ma.set_fill_value(radar.fields['velocity']['data'], np.nan)\n",
    "                    meanvelal = np.mean(radar.fields['velocity']['data'][sw_start:sw_end,:].filled()[~np.isnan(radar.fields['velocity']['data'][sw_start:sw_end,:].filled())])\n",
    "                    meanveldeal = np.mean(vede['data'][sw_start:sw_end,:].filled()[~np.isnan(vede['data'][sw_start:sw_end,:].filled())])\n",
    "                    if np.abs(meanvelal-meanveldeal) < nyq: #nyq is an arbitrary threshold and should be tuned\n",
    "                        break\n",
    "                    if bins[np.where(hist==np.min(hist[find_nearest(bins,1):find_nearest(bins,6)]))[0][0]]+counter*0.5 < np.amax(bins):\n",
    "                        if (meanvelal-meanveldeal) > 0:\n",
    "                            vede['data'][sw_start:sw_end,:] += 2*nyq\n",
    "                        else:\n",
    "                            vede['data'][sw_start:sw_end,:] -= 2*nyq\n",
    "                        break\n",
    "                counter+=1\n",
    "            \n",
    "        #put alias fix inside here instead of calling it to make it more portable\n",
    "        delta=3\n",
    "        mean = convolve(vede['data'][sw_start:sw_end,:],np.ones((delta,delta))/delta**2.)\n",
    "        mean[0,:] = vede['data'][sw_start:sw_end,:][0,:]\n",
    "        mean[-1,:] = vede['data'][sw_start:sw_end,:][-1,:]\n",
    "        var = vede['data'][sw_start:sw_end,:] - mean\n",
    "\n",
    "        high_idx = np.logical_and(var > nyq, var < 4*nyq)\n",
    "        low_idx = np.logical_and(var < -nyq, var > -4*nyq)\n",
    "\n",
    "        vede['data'][sw_start:sw_end,:][high_idx] = vede['data'][sw_start:sw_end,:][high_idx] - 2*nyq\n",
    "        vede['data'][sw_start:sw_end,:][low_idx] = vede['data'][sw_start:sw_end,:][low_idx] + 2*nyq\n",
    "\n",
    "        #corrects ground clutter by arbitrarily setting the velocity equal to 0 where spectrum width is less than 0.075 m/s\n",
    "        if PPIGC_flag == True:\n",
    "            if radar.scan_type == 'ppi':\n",
    "                sw = radar.fields['spectrum_width']['data'][sw_start:sw_end,:].filled()\n",
    "                vel = radar.fields['velocity']['data'][sw_start:sw_end,:].filled()\n",
    "                mask = sw<0.1\n",
    "                vede['data'][sw_start:sw_end,:] = np.where(~mask,vede['data'][sw_start:sw_end,:],0)\n",
    "\n",
    "        velocity_dealiased['data'][sw_start:sw_end,:] = vede['data'][sw_start:sw_end,:]\n",
    "        velocity_dealiased['data'][sw_start:sw_end,:] = alias_fix(velocity_dealiased['data'][sw_start:sw_end,:],nyq,delta=9)\n",
    "    radar.add_field('corrected_velocity', velocity_dealiased, replace_existing=True)\n",
    "\n",
    "    return radar\n",
    "\n",
    "def alias_fix(vel,nyq,delta=3):\n",
    "    '''\n",
    "    !!!!!!!!!!!!!!!!!!\n",
    "    Removes dealiasing errors around the periphery of a folded region\n",
    "\n",
    "    Parameters: velocity array (array), nyquist velocity (number), size of window (int, must be odd, unity is no change)\n",
    "    Returns: cleaned velocity array (array)\n",
    "    '''\n",
    "    mean = convolve(vel,np.ones((delta,delta))/delta**2.)\n",
    "    mean[0,:] = vel[0,:]\n",
    "    mean[-1,:] = vel[-1,:]\n",
    "    var = vel - mean\n",
    "\n",
    "    high_idx = np.logical_and(var > nyq, var < 4*nyq)\n",
    "    low_idx = np.logical_and(var < -nyq, var > -4*nyq)\n",
    "\n",
    "    vel[high_idx] = vel[high_idx] - 2*nyq\n",
    "    vel[low_idx] = vel[low_idx] + 2*nyq\n",
    "\n",
    "    return vel\n",
    "\n",
    "def get_radar_from_aws(site, datetime_t, datetime_te):\n",
    "    \"\"\"\n",
    "    Get the closest volume of NEXRAD data to a particular datetime.\n",
    "    Parameters\n",
    "    ----------\n",
    "    site : string\n",
    "        four letter radar designation\n",
    "    datetime_t : datetime\n",
    "        desired date time\n",
    "    Returns\n",
    "    -------\n",
    "    radar : Py-ART Radar Object\n",
    "        Radar closest to the queried datetime\n",
    "    \"\"\"\n",
    "\n",
    "    # First create the query string for the bucket knowing\n",
    "    # how NOAA and AWS store the data\n",
    "    my_pref = datetime_t.strftime('%Y/%m/%d/') + site\n",
    "\n",
    "    # Connect to the bucket\n",
    "    conn = S3Connection(anon = True)\n",
    "    bucket = conn.get_bucket('noaa-nexrad-level2')\n",
    "\n",
    "    # Get a list of files\n",
    "    bucket_list = list(bucket.list(prefix = my_pref))\n",
    "\n",
    "    # we are going to create a list of keys and datetimes to allow easy searching\n",
    "    keys = []\n",
    "    datetimes = []\n",
    "\n",
    "    # populate the list\n",
    "    for i in range(len(bucket_list)):\n",
    "        this_str = str(bucket_list[i].key)\n",
    "        if 'gz' in this_str:\n",
    "            endme = this_str[-22:-4]\n",
    "            fmt = '%Y%m%d_%H%M%S_V0'\n",
    "            dt = datetime.strptime(endme, fmt)\n",
    "            datetimes.append(dt)\n",
    "            keys.append(bucket_list[i])\n",
    "\n",
    "        if this_str[-3::] == 'V06':\n",
    "            endme = this_str[-19::]\n",
    "            fmt = '%Y%m%d_%H%M%S_V06'\n",
    "            dt = datetime.strptime(endme, fmt)\n",
    "            datetimes.append(dt)\n",
    "            keys.append(bucket_list[i])\n",
    "\n",
    "    # find the closest available radar to your datetime\n",
    "    closest_datetime_b = _nearestDate(datetimes, datetime_t)\n",
    "    closest_datetime_e = _nearestDate(datetimes, datetime_te)\n",
    "\n",
    "    index_b = datetimes.index(closest_datetime_b)\n",
    "    index_e = datetimes.index(closest_datetime_e)\n",
    "\n",
    "    radar_namelist = keys[index_b:index_e+1]\n",
    "    radar_list=[]\n",
    "    for i in range(np.shape(radar_namelist)[0]):\n",
    "        localfile = tempfile.NamedTemporaryFile()\n",
    "        radar_namelist[i].get_contents_to_filename(localfile.name)\n",
    "        radar_list.append(pyart.io.read(localfile.name))\n",
    "    return radar_namelist,radar_list\n",
    "\n",
    "def getLocation(lat1, lon1, brng, distancekm):\n",
    "    lat1 = lat1 * np.pi / 180.0\n",
    "    lon1 = lon1 * np.pi / 180.0\n",
    "    #earth radius\n",
    "    R = 6378.1\n",
    "    #R = ~ 3959 MilesR = 3959\n",
    "    bearing = (brng / 90.)* np.pi / 2.\n",
    "\n",
    "    lat2 = np.arcsin(np.sin(lat1) * np.cos(distancekm/R) + np.cos(lat1) * np.sin(distancekm/R) * np.cos(bearing))\n",
    "    lon2 = lon1 + np.arctan2(np.sin(bearing)*np.sin(distancekm/R)*np.cos(lat1),np.cos(distancekm/R)-np.sin(lat1)*np.sin(lat2))\n",
    "    lon2 = 180.0 * lon2 / np.pi\n",
    "    lat2 = 180.0 * lat2 / np.pi\n",
    "    return lat2, lon2\n",
    "\n",
    "def _nearestDate(dates, pivot):\n",
    "    return min(dates, key=lambda x: abs(x - pivot))\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    '''\n",
    "    Function to find index of the array in which the value is closest to\n",
    "\n",
    "    Parameters: array (array), value (number)\n",
    "    Returns: index (int)\n",
    "\n",
    "    Example: xind = CM1calc.find_nearest(x,5)\n",
    "    '''\n",
    "\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx\n",
    "\n",
    "\n",
    "def vehicle_correction_vad(radar,df):\n",
    "    '''\n",
    "    Function that creates a 'vad_corrected_velocity' field that can be used for vad calculations, \n",
    "    but should be general enough to use for stationary VADs as well as moving PPIs. \n",
    "    Other than adding the new field, the radar times are smoothly interpolated and the azimuths are \n",
    "    corrected via the GPS pandas dataframe.\n",
    "    \n",
    "    Parameters: pyart radar object (object), pandas dataframe of appropriate radarGPS file (dataframe)\n",
    "    Returns: pyart radar object (object), speed (float), speed variance (float), bearing (float), bearing variance (float), \n",
    "             latitude (float), latitude variance (float), longitude (float), longitude variance (float)\n",
    "    \n",
    "    Example: radar, velmean, velvar, bearmean, bearvar, latmean, latvar, lonmean, lonvar = vehicle_correction_vad(radar,df)\n",
    "\n",
    "    p.s. only works if the velocity is already dealiased and there is a 'corrected_velocity' field\n",
    "         also only works if a single sweep is extracted, example: radar = radar.extract_sweeps([0])\n",
    "    '''\n",
    "    #for i in df:\n",
    "    #orders the time to increase monotonically instead of having a massive step jump in the middle\n",
    "    roll_mag = (np.argmax(np.abs(np.gradient(radar.time['data'])))+1)\n",
    "    times = np.roll(radar.time['data'],-roll_mag) \n",
    "    \n",
    "    #a complicated way to create linear increasing times (instead of steps) that start at 0 seconds after the time datum and increase to the middle of the second max time plateau (if confused, plotting it is helpful)\n",
    "    #from now on, we are going to assume ray_times is the fractional seconds after the time datum the ray is gathered, and we need to roll it back to match with the rest of the data\n",
    "    ray_times = np.roll(np.arange(0,((np.unique(times)[-2])/(find_nearest(times,np.unique(times)[-2])+int(np.sum(radar.time['data']==np.unique(times)[-2])/2)))*len(times)+1e-11,((np.unique(times)[-2])/(find_nearest(times,np.unique(times)[-2])+int(np.sum(radar.time['data']==np.unique(times)[-2])/2)))),roll_mag)\n",
    "\n",
    "    radar.time['data']=ray_times\n",
    "    \n",
    "    #df['datetime'] = pd.to_datetime(df['ddmmyy']+df['hhmmss[UTC]'], format='%d%m%y%H%M%S')\n",
    "    df['datetime'] = [datetime.strptime(d,'%d%m%y%H%M%S') for d in df['ddmmyy']+[f'{h:06}' for h in df['hhmmss[UTC]'].astype(int)]]\n",
    "    beginscanindex = df.loc[df['datetime'] == datetime.strptime(radar.time['units'],'seconds since %Y-%m-%dT%H:%M:%SZ')].index\n",
    "    endscanindex = df.loc[df['datetime'] == datetime.strptime(radar.time['units'],'seconds since %Y-%m-%dT%H:%M:%SZ')].index+np.ceil(np.amax(ray_times))+1\n",
    "    if len(beginscanindex) == 0: # MAKES IT SO THAT IF THE DATETIME IS MISSING IT SKIPS THE FILE\n",
    "        return None#, None, None, None, None, None, None, None\n",
    "    dfscan = df.iloc[beginscanindex[0].astype(int):endscanindex[0].astype(int)]\n",
    "    dfscan = dfscan.astype({'Bearing[degrees]': 'float'})\n",
    "    dfscan = dfscan.astype({'Velocity[knots]': 'float'})\n",
    "        \n",
    "    ray_bearings = np.interp(ray_times,np.arange(len(dfscan)),dfscan['Bearing[degrees]'])\n",
    "    ray_speeds = np.interp(ray_times,np.arange(len(dfscan)),dfscan['Velocity[knots]'])\n",
    "        \n",
    "    #    print('velocity [kts]',dfscan['Velocity[knots]'].mean(),'+-',dfscan['Velocity[knots]'].var())\n",
    "    speed = dfscan['Velocity[knots]'].mean()\n",
    "    #    print('bearing',dfscan['Bearing[degrees]'].mean(),'+-',dfscan['Bearing[degrees]'].var())\n",
    "    bearing = dfscan['Bearing[degrees]'].mean()\n",
    "    #    print('latitude',dfscan['Latitude'].astype(float).mean(),'+-',dfscan['Latitude'].astype(float).var())\n",
    "    lat = dfscan['Latitude'].astype(float).mean()\n",
    "    #    print('longitude',dfscan['Longitude'].astype(float).mean(),'+-',dfscan['Longitude'].astype(float).var())\n",
    "    lon = dfscan['Longitude'].astype(float).mean()\n",
    "        \n",
    "    radar.azimuth['data'] += ray_bearings[:-1] #bearing\n",
    "        \n",
    "    rad_vel = copy.deepcopy(radar.fields['corrected_velocity'])\n",
    "        \n",
    "    rad_vel['data']+=(np.cos(np.deg2rad(radar.azimuth['data']-ray_bearings[:-1]))*(ray_speeds[:-1]/1.94384)*np.cos(np.deg2rad(radar.fixed_angle['data'][0])))[:,np.newaxis]\n",
    "        \n",
    "    #fix mask, remove points very close to radar as well as the very last bin, more often than not, = bad data\n",
    "    rad_vel['data'].mask[:,:5] = True\n",
    "    rad_vel['data'].mask[:,-1] = True\n",
    "    radar.add_field('vad_corrected_velocity', rad_vel, replace_existing=True)\n",
    "        \n",
    "    return radar, dfscan['Velocity[knots]'].mean(),dfscan['Velocity[knots]'].var(),dfscan['Bearing[degrees]'].mean(),dfscan['Bearing[degrees]'].var(),dfscan['Latitude'].astype(float).mean(),dfscan['Latitude'].astype(float).var(),dfscan['Longitude'].astype(float).mean(),dfscan['Longitude'].astype(float).var()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7a70925-042a-491c-bdc1-652cf765778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stackoverflow (https://stackoverflow.com/questions/639695/how-to-convert-latitude-or-longitude-to-meters)\n",
    "# originally in javascript\n",
    "def measure(lat1, lon1, lat2, lon2):  # generally used geo measurement function\n",
    "    R = 6378.137 # Radius of earth in KM\n",
    "    dLat = lat2 * np.pi / 180 - lat1 * np.pi / 180;\n",
    "    dLon = lon2 * np.pi / 180 - lon1 * np.pi / 180;\n",
    "    a = np.sin(dLat/2) * np.sin(dLat/2) + np.cos(lat1 * np.pi / 180) * np.cos(lat2 * np.pi / 180) * np.sin(dLon/2) * np.sin(dLon/2)\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = R * c\n",
    "    #d_meters = d * 1000\n",
    "    return d # km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0ef6454-b6ea-4590-a146-6fe606957685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_storm_tobac(tobac_file, cell_number):\n",
    "    '''\n",
    "    This function will use the data created by using tobac to obtain the \n",
    "    information associated with a desired cell.\n",
    "    Returns the latitudes, longitudes, and times associated with the desired cell.\n",
    "    '''\n",
    "    tobac_features_xr = xr.open_dataset(tobac_file)\n",
    "    idx = tobac_features_xr['idx'].data\n",
    "    cell = tobac_features_xr['cell'].data\n",
    "    morton_storm_indeces_idx = np.where(idx == cell_number)\n",
    "    morton_storm_indeces = np.where(cell == cell_number)\n",
    "    tobac_times = tobac_features_xr['time']\n",
    "    tobac_lats = np.array(tobac_features_xr['latitude'])\n",
    "    tobac_lons = np.array(tobac_features_xr['longitude'])\n",
    "    morton_tobac_lats = tobac_lats[morton_storm_indeces]\n",
    "    morton_tobac_lons = tobac_lons[morton_storm_indeces]\n",
    "    morton_tobac_times = tobac_times[morton_storm_indeces]\n",
    "    morton_cell_29 = cell[morton_storm_indeces]\n",
    "    morton_tobac_times_datetime = morton_tobac_times.astype('datetime64[s]')\n",
    "    \n",
    "    return morton_tobac_lats, morton_tobac_lons, morton_cell_29, morton_tobac_times_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39661c92-2062-4599-be6d-e8f2976c5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_tobac_time(netcdf_list, morton_tobac_lats, morton_tobac_lons, morton_tobac_times_datetime):\n",
    "    '''\n",
    "    To run this function, you must make sure you've pre-defined the generic find_nearest function first.\n",
    "    netcdf_file = a single netcdf file\n",
    "    morton_tobac_times_datetime = the list made from the get_storm_tobac function\n",
    "    '''\n",
    "    time_list = []\n",
    "    for netcdf_file in netcdf_list:\n",
    "        time_yoink = netcdf_file[-15:-3]\n",
    "        #print(time_yoink)\n",
    "        time_yoink_dt = datetime.strptime(time_yoink, '%y%m%d%H%M%S')\n",
    "        time_list.append(time_yoink_dt)\n",
    "        \n",
    "    time_yoink_dt_array = np.array(time_list)\n",
    "    time_yoink_dt_convert = time_yoink_dt_array.astype('datetime64[s]')\n",
    "    time_yoink_dt_series = pd.Series(time_yoink_dt_convert)\n",
    "    \n",
    "    nearest_tobac_index = []\n",
    "    for time in time_yoink_dt_convert:\n",
    "        tobac_index = find_nearest(morton_tobac_times_datetime.data, time)\n",
    "        nearest_tobac_index.append(tobac_index)\n",
    "        \n",
    "    tobac_times_closest = morton_tobac_times_datetime[nearest_tobac_index]\n",
    "    series_tobac_times = pd.Series(tobac_times_closest)\n",
    "    series_tobac_indeces = pd.Series(nearest_tobac_index)\n",
    "    \n",
    "    tobac_lats_closest = morton_tobac_lats[nearest_tobac_index]\n",
    "    series_tobac_lats = pd.Series(tobac_lats_closest)\n",
    "    tobac_lons_closest = morton_tobac_lons[nearest_tobac_index]\n",
    "    series_tobac_lons = pd.Series(tobac_lons_closest)\n",
    "\n",
    "    return time_yoink_dt_series, series_tobac_times, series_tobac_indeces, series_tobac_lats, series_tobac_lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ff6e148-9749-450e-a141-aebf584270dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vad_df(netcdf_list, gps_file, radar_array, velmean_array, velvar_array, bearmean_array,\n",
    "           latmean_array, latvar_array, lonmean_array, lonvar_array, time_yoink_dt_series,\n",
    "          series_tobac_times, series_tobac_indeces, series_tobac_lats, series_tobac_lons):\n",
    "    '''\n",
    "    This function uses alex's vehicle_correction_vad to create the below fields from the input\n",
    "    radar object. These fields and the tobac information are all put into one pandas DataFrame.\n",
    "    '''\n",
    "    for file in netcdf_list:\n",
    "        print(file)\n",
    "        try:\n",
    "            gps_file['ddmmyy'] = gps_file['ddmmyy'].astype(str)\n",
    "            gps_file['hhmmss[UTC]'] = gps_file['hhmmss[UTC]'].astype(str)\n",
    "            read = pyart.io.read(file)\n",
    "            all_vehicle_correction = vehicle_correction_vad(read, gps_file)\n",
    "            if all_vehicle_correction == None:\n",
    "                print('broken')\n",
    "                continue\n",
    "            radar_array.append(all_vehicle_correction[0])\n",
    "            velmean_array.append(all_vehicle_correction[1])\n",
    "            velvar_array.append(all_vehicle_correction[2])\n",
    "            bearmean_array.append(all_vehicle_correction[3])\n",
    "            latmean_array.append(all_vehicle_correction[5])\n",
    "            latvar_array.append(all_vehicle_correction[6])\n",
    "            lonmean_array.append(all_vehicle_correction[7])\n",
    "            lonvar_array.append(all_vehicle_correction[8])\n",
    "        except Keyerror:\n",
    "            pass\n",
    "\n",
    "    radar_column = pd.Series(radar_array)\n",
    "    velmean_column = pd.Series(velmean_array)\n",
    "    velvar_column = pd.Series(velvar_array)\n",
    "    bearmean_column = pd.Series(bearmean_array)\n",
    "    latmean_column = pd.Series(latmean_array)\n",
    "    latvar_column = pd.Series(latvar_array)\n",
    "    lonmean_column = pd.Series(lonmean_array)\n",
    "    lonvar_column = pd.Series(lonvar_array)\n",
    "\n",
    "    distance_from_storm = measure(series_tobac_lats, series_tobac_lons, \n",
    "                                  latmean_column, lonmean_column)\n",
    "    distance_from_storm_column = pd.Series(distance_from_storm)\n",
    "\n",
    "    df = pd.DataFrame(pd.concat([time_yoink_dt_series,radar_column, velmean_column, velvar_column, \n",
    "                                 bearmean_column, latmean_column, latvar_column, lonmean_column, \n",
    "                                 lonvar_column, series_tobac_times, series_tobac_indeces, \n",
    "                                 series_tobac_lats, series_tobac_lons, distance_from_storm_column], axis = 1))\n",
    "    \n",
    "    df.rename(columns={0: 'Datetime', 1: 'Radar', 2: 'Velmean', 3: 'Velvar', 4: 'Bearmean', 5: 'Latmean', \n",
    "                            6: 'Latvar', 7: 'Lonmean', 8: 'Lonvar', 9: 'tobac_times',\n",
    "                            10: 'tobac_indeces', 11: 'tobac_lats', 12: 'tobac_lons', \n",
    "                           13: 'Distance_From_Storm [km]'}, inplace  = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ca7f48-2587-45ad-870b-aeb92e555391",
   "metadata": {},
   "source": [
    "# Testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7dcff945-b7ca-43fb-a83e-f0b265b5e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "ka1_vads = sorted(glob.glob('/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/*.nc'))\n",
    "ka2_vads = sorted(glob.glob('/Users/juliabman/Desktop/vads/vads_radar_objects/ka2/05232022/*.nc'))\n",
    "ka1gps = pd.read_csv('/Users/juliabman/Desktop/research2024/GPS_Ka1_20220523.txt')\n",
    "ka2gps = pd.read_csv('/Users/juliabman/Desktop/research2024/GPS_Ka2_20220523.txt')\n",
    "tobac_file = '/Users/juliabman/Desktop/research2024/tobac_Save/Track.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e55f4d9-23ea-4688-af90-9667ba569629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ka1_vads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df48d5e8-9021-437f-a6e0-1a8dc7f20a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ka2_vads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a598c821-b522-4560-8cf7-0b96b09fae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4f/9s_4__q16tx5t8vmww4mv03h0000gn/T/ipykernel_45591/2076589757.py:19: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  morton_tobac_times_datetime = morton_tobac_times.astype('datetime64[s]')\n"
     ]
    }
   ],
   "source": [
    "cell_lats, cell_lons, cell_indeces, cell_times = get_storm_tobac(tobac_file, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f23c01c-7dd1-471b-9b38-d5ab105d4e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(cell_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3fcc515-0830-407c-b1bd-d30b6b0141ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_times, morton_times, morton_indeces, morton_lats, morton_lons = nearest_tobac_time(ka1_vads, \n",
    "                                                                                           cell_lats, \n",
    "                                                                                           cell_lons, \n",
    "                                                                                           cell_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5718281-c8ed-4ea4-abba-7002b97f66a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2022-05-23 22:21:19\n",
       "1    2022-05-23 22:22:19\n",
       "2    2022-05-23 22:23:21\n",
       "3    2022-05-23 22:23:51\n",
       "4    2022-05-23 22:25:51\n",
       "             ...        \n",
       "77   2022-05-24 00:00:10\n",
       "78   2022-05-24 00:00:39\n",
       "79   2022-05-24 00:01:10\n",
       "80   2022-05-24 00:01:39\n",
       "81   2022-05-24 00:03:09\n",
       "Length: 82, dtype: datetime64[s]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vad_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78fd035e-1258-42ac-a5a6-7c9ed1400bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2022-05-23 22:21:17\n",
       "1    2022-05-23 22:21:17\n",
       "2    2022-05-23 22:21:17\n",
       "3    2022-05-23 22:25:49\n",
       "4    2022-05-23 22:25:49\n",
       "             ...        \n",
       "77   2022-05-23 23:58:17\n",
       "78   2022-05-23 23:58:17\n",
       "79   2022-05-24 00:03:14\n",
       "80   2022-05-24 00:03:14\n",
       "81   2022-05-24 00:03:14\n",
       "Length: 82, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morton_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c56a827a-3143-48c4-b7e0-bb20e09d09f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "77    17\n",
       "78    17\n",
       "79    18\n",
       "80    18\n",
       "81    18\n",
       "Length: 82, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morton_indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7faec2d2-10f0-410d-8ec6-2c9dc20ff37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     33.725464\n",
       "1     33.725464\n",
       "2     33.725464\n",
       "3     33.744333\n",
       "4     33.744333\n",
       "        ...    \n",
       "77    33.903952\n",
       "78    33.903952\n",
       "79    33.900867\n",
       "80    33.900867\n",
       "81    33.900867\n",
       "Length: 82, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morton_lats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01cccdb9-9af9-480f-a80b-ee4f7a683c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -103.115808\n",
       "1    -103.115808\n",
       "2    -103.115808\n",
       "3    -103.101291\n",
       "4    -103.101291\n",
       "         ...    \n",
       "77   -102.746264\n",
       "78   -102.746264\n",
       "79   -102.732445\n",
       "80   -102.732445\n",
       "81   -102.732445\n",
       "Length: 82, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morton_lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0bbba1f1-73c6-4c0b-9f8b-1e4ebd4c0ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523222119.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523222219.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523222321.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523222351.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523222551.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523222620.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523222649.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523222718.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523222747.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523222816.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523222914.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523222943.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523223013.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523223042.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523223111.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523223140.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523223209.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523223734.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523223834.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523223932.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523224101.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523224130.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523225510.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523225540.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523225610.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523225740.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523225809.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523225910.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523230040.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523230141.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523230240.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523231558.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523231627.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523231657.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523231726.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523231826.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523231925.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523231955.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232025.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232055.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232125.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232155.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232224.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232255.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232455.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232555.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232624.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232654.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232724.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232753.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232852.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523232921.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523234511.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523234542.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523234612.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523234642.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523234712.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523234742.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523234812.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523234843.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523234913.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523234942.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235043.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235143.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235212.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235242.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235312.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235342.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235411.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235510.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235541.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235611.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235640.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235710.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235740.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235840.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220523235910.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220524000010.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220524000039.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220524000110.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220524000139.nc\n",
      "/Users/juliabman/Desktop/vads/vads_radar_objects/ka1/05232022/dealiased_terminal_corrected_20220524000309.nc\n"
     ]
    }
   ],
   "source": [
    "radar_array = []\n",
    "velmean_array = []\n",
    "velvar_array = []\n",
    "bearmean_array = []\n",
    "latmean_array = []\n",
    "latvar_array = []\n",
    "lonmean_array = []\n",
    "lonvar_array = []\n",
    "ka1_df = vad_df(ka1_vads, ka1gps, radar_array, velmean_array, velvar_array, bearmean_array,\n",
    "           latmean_array, latvar_array, lonmean_array, lonvar_array, vad_times,\n",
    "          morton_times, morton_indeces, morton_lats, morton_lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81ab6583-391a-4e9e-93ef-fa62867c7285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Radar</th>\n",
       "      <th>Velmean</th>\n",
       "      <th>Velvar</th>\n",
       "      <th>Bearmean</th>\n",
       "      <th>Latmean</th>\n",
       "      <th>Latvar</th>\n",
       "      <th>Lonmean</th>\n",
       "      <th>Lonvar</th>\n",
       "      <th>tobac_times</th>\n",
       "      <th>tobac_indeces</th>\n",
       "      <th>tobac_lats</th>\n",
       "      <th>tobac_lons</th>\n",
       "      <th>Distance_From_Storm [km]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-23 22:21:19</td>\n",
       "      <td>&lt;pyart.core.radar.Radar object at 0x328cb5790&gt;</td>\n",
       "      <td>62.339348</td>\n",
       "      <td>0.493868</td>\n",
       "      <td>270.572609</td>\n",
       "      <td>33.873966</td>\n",
       "      <td>1.609869e-09</td>\n",
       "      <td>-102.828631</td>\n",
       "      <td>2.176506e-05</td>\n",
       "      <td>2022-05-23 22:21:17</td>\n",
       "      <td>0</td>\n",
       "      <td>33.725464</td>\n",
       "      <td>-103.115808</td>\n",
       "      <td>31.288944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-23 22:22:19</td>\n",
       "      <td>&lt;pyart.core.radar.Radar object at 0x30fc22520&gt;</td>\n",
       "      <td>59.926889</td>\n",
       "      <td>2.204317</td>\n",
       "      <td>270.554889</td>\n",
       "      <td>33.874117</td>\n",
       "      <td>1.224962e-09</td>\n",
       "      <td>-102.848543</td>\n",
       "      <td>1.928859e-05</td>\n",
       "      <td>2022-05-23 22:21:17</td>\n",
       "      <td>0</td>\n",
       "      <td>33.725464</td>\n",
       "      <td>-103.115808</td>\n",
       "      <td>29.750265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-23 22:23:21</td>\n",
       "      <td>&lt;pyart.core.radar.Radar object at 0x107acfe80&gt;</td>\n",
       "      <td>53.586200</td>\n",
       "      <td>0.585208</td>\n",
       "      <td>265.355200</td>\n",
       "      <td>33.872104</td>\n",
       "      <td>2.886377e-07</td>\n",
       "      <td>-102.875865</td>\n",
       "      <td>7.335083e-05</td>\n",
       "      <td>2022-05-23 22:21:17</td>\n",
       "      <td>0</td>\n",
       "      <td>33.725464</td>\n",
       "      <td>-103.115808</td>\n",
       "      <td>27.552471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-23 22:23:51</td>\n",
       "      <td>&lt;pyart.core.radar.Radar object at 0x3068a5040&gt;</td>\n",
       "      <td>53.712037</td>\n",
       "      <td>0.517420</td>\n",
       "      <td>270.823704</td>\n",
       "      <td>33.871856</td>\n",
       "      <td>3.721434e-09</td>\n",
       "      <td>-102.877905</td>\n",
       "      <td>2.208765e-05</td>\n",
       "      <td>2022-05-23 22:25:49</td>\n",
       "      <td>1</td>\n",
       "      <td>33.744333</td>\n",
       "      <td>-103.101291</td>\n",
       "      <td>25.068904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-23 22:25:51</td>\n",
       "      <td>&lt;pyart.core.radar.Radar object at 0x328bf0d60&gt;</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>179.230000</td>\n",
       "      <td>33.871881</td>\n",
       "      <td>1.792075e-12</td>\n",
       "      <td>-102.898984</td>\n",
       "      <td>2.900816e-11</td>\n",
       "      <td>2022-05-23 22:25:49</td>\n",
       "      <td>1</td>\n",
       "      <td>33.744333</td>\n",
       "      <td>-103.101291</td>\n",
       "      <td>23.489548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2022-05-24 00:00:10</td>\n",
       "      <td>&lt;pyart.core.radar.Radar object at 0x30fca7e50&gt;</td>\n",
       "      <td>5.490640</td>\n",
       "      <td>173.986013</td>\n",
       "      <td>239.566352</td>\n",
       "      <td>33.792004</td>\n",
       "      <td>3.526687e-05</td>\n",
       "      <td>-102.644818</td>\n",
       "      <td>1.318757e-06</td>\n",
       "      <td>2022-05-23 23:58:17</td>\n",
       "      <td>17</td>\n",
       "      <td>33.903952</td>\n",
       "      <td>-102.746264</td>\n",
       "      <td>15.597101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2022-05-24 00:00:39</td>\n",
       "      <td>&lt;pyart.core.radar.Radar object at 0x30fc8c100&gt;</td>\n",
       "      <td>36.328511</td>\n",
       "      <td>10.928426</td>\n",
       "      <td>1.018723</td>\n",
       "      <td>33.772682</td>\n",
       "      <td>5.268943e-06</td>\n",
       "      <td>-102.642528</td>\n",
       "      <td>2.740749e-09</td>\n",
       "      <td>2022-05-23 23:58:17</td>\n",
       "      <td>17</td>\n",
       "      <td>33.903952</td>\n",
       "      <td>-102.746264</td>\n",
       "      <td>17.479725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2022-05-24 00:01:10</td>\n",
       "      <td>&lt;pyart.core.radar.Radar object at 0x30fca7cd0&gt;</td>\n",
       "      <td>3.973097</td>\n",
       "      <td>137.133658</td>\n",
       "      <td>248.861781</td>\n",
       "      <td>33.793175</td>\n",
       "      <td>1.024336e-05</td>\n",
       "      <td>-102.644966</td>\n",
       "      <td>1.007866e-06</td>\n",
       "      <td>2022-05-24 00:03:14</td>\n",
       "      <td>18</td>\n",
       "      <td>33.900867</td>\n",
       "      <td>-102.732445</td>\n",
       "      <td>14.461335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2022-05-24 00:01:39</td>\n",
       "      <td>&lt;pyart.core.radar.Radar object at 0x30fca7790&gt;</td>\n",
       "      <td>43.196667</td>\n",
       "      <td>15.037367</td>\n",
       "      <td>38.183750</td>\n",
       "      <td>33.784412</td>\n",
       "      <td>8.276087e-06</td>\n",
       "      <td>-102.642297</td>\n",
       "      <td>2.191911e-09</td>\n",
       "      <td>2022-05-24 00:03:14</td>\n",
       "      <td>18</td>\n",
       "      <td>33.900867</td>\n",
       "      <td>-102.732445</td>\n",
       "      <td>15.412055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2022-05-24 00:03:09</td>\n",
       "      <td>&lt;pyart.core.radar.Radar object at 0x30fca75b0&gt;</td>\n",
       "      <td>7.042029</td>\n",
       "      <td>5.056002</td>\n",
       "      <td>267.491884</td>\n",
       "      <td>33.793953</td>\n",
       "      <td>6.289429e-11</td>\n",
       "      <td>-102.643288</td>\n",
       "      <td>6.808051e-07</td>\n",
       "      <td>2022-05-24 00:03:14</td>\n",
       "      <td>18</td>\n",
       "      <td>33.900867</td>\n",
       "      <td>-102.732445</td>\n",
       "      <td>14.477302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime                                           Radar  \\\n",
       "0  2022-05-23 22:21:19  <pyart.core.radar.Radar object at 0x328cb5790>   \n",
       "1  2022-05-23 22:22:19  <pyart.core.radar.Radar object at 0x30fc22520>   \n",
       "2  2022-05-23 22:23:21  <pyart.core.radar.Radar object at 0x107acfe80>   \n",
       "3  2022-05-23 22:23:51  <pyart.core.radar.Radar object at 0x3068a5040>   \n",
       "4  2022-05-23 22:25:51  <pyart.core.radar.Radar object at 0x328bf0d60>   \n",
       "..                 ...                                             ...   \n",
       "77 2022-05-24 00:00:10  <pyart.core.radar.Radar object at 0x30fca7e50>   \n",
       "78 2022-05-24 00:00:39  <pyart.core.radar.Radar object at 0x30fc8c100>   \n",
       "79 2022-05-24 00:01:10  <pyart.core.radar.Radar object at 0x30fca7cd0>   \n",
       "80 2022-05-24 00:01:39  <pyart.core.radar.Radar object at 0x30fca7790>   \n",
       "81 2022-05-24 00:03:09  <pyart.core.radar.Radar object at 0x30fca75b0>   \n",
       "\n",
       "      Velmean      Velvar    Bearmean    Latmean        Latvar     Lonmean  \\\n",
       "0   62.339348    0.493868  270.572609  33.873966  1.609869e-09 -102.828631   \n",
       "1   59.926889    2.204317  270.554889  33.874117  1.224962e-09 -102.848543   \n",
       "2   53.586200    0.585208  265.355200  33.872104  2.886377e-07 -102.875865   \n",
       "3   53.712037    0.517420  270.823704  33.871856  3.721434e-09 -102.877905   \n",
       "4    0.009848    0.002146  179.230000  33.871881  1.792075e-12 -102.898984   \n",
       "..        ...         ...         ...        ...           ...         ...   \n",
       "77   5.490640  173.986013  239.566352  33.792004  3.526687e-05 -102.644818   \n",
       "78  36.328511   10.928426    1.018723  33.772682  5.268943e-06 -102.642528   \n",
       "79   3.973097  137.133658  248.861781  33.793175  1.024336e-05 -102.644966   \n",
       "80  43.196667   15.037367   38.183750  33.784412  8.276087e-06 -102.642297   \n",
       "81   7.042029    5.056002  267.491884  33.793953  6.289429e-11 -102.643288   \n",
       "\n",
       "          Lonvar         tobac_times  tobac_indeces  tobac_lats  tobac_lons  \\\n",
       "0   2.176506e-05 2022-05-23 22:21:17              0   33.725464 -103.115808   \n",
       "1   1.928859e-05 2022-05-23 22:21:17              0   33.725464 -103.115808   \n",
       "2   7.335083e-05 2022-05-23 22:21:17              0   33.725464 -103.115808   \n",
       "3   2.208765e-05 2022-05-23 22:25:49              1   33.744333 -103.101291   \n",
       "4   2.900816e-11 2022-05-23 22:25:49              1   33.744333 -103.101291   \n",
       "..           ...                 ...            ...         ...         ...   \n",
       "77  1.318757e-06 2022-05-23 23:58:17             17   33.903952 -102.746264   \n",
       "78  2.740749e-09 2022-05-23 23:58:17             17   33.903952 -102.746264   \n",
       "79  1.007866e-06 2022-05-24 00:03:14             18   33.900867 -102.732445   \n",
       "80  2.191911e-09 2022-05-24 00:03:14             18   33.900867 -102.732445   \n",
       "81  6.808051e-07 2022-05-24 00:03:14             18   33.900867 -102.732445   \n",
       "\n",
       "    Distance_From_Storm [km]  \n",
       "0                  31.288944  \n",
       "1                  29.750265  \n",
       "2                  27.552471  \n",
       "3                  25.068904  \n",
       "4                  23.489548  \n",
       "..                       ...  \n",
       "77                 15.597101  \n",
       "78                 17.479725  \n",
       "79                 14.461335  \n",
       "80                 15.412055  \n",
       "81                 14.477302  \n",
       "\n",
       "[82 rows x 14 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ka1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa60cb50-3eb6-4bd3-bb3b-05d7c3119acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ka1_df.to_csv(path_or_buf = '/Users/juliabman/Desktop/vads/vad_dfs/ka1/05232022/ka1_vads_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c922813-8a29-46fb-a32e-d25acfcadf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ka2_df.to_csv(path_or_buf = '/Users/juliabman/Desktop/vads/vad_dfs/ka2/05232022/ka2_vads_df')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
